# -*- coding: utf-8 -*-
"""rho_score.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12rHBw2_K-fHt6xxvF8Fq0tkVm-gEJKsY

## **Guide to Generate RoHo Score File (roho_scores.tsv)**

Install UShER Toolkit and matUtils


```
conda create -n usher_env -c bioconda -c conda-forge usher
```

Generate RoHo Score Using matUtils


```
matUtils summary -i public-2021-06-09.all.masked.nextclade.pangolin.pb.gz -R roho_scores.tsv

```

Each row = one mutation event in the tree
Each column contains information needed to compute RoHo:

Column	Description
mutation: Nucleotide mutation (e.g., A22106T)

parent_node:	Node in the tree where the mutation occurred

child_count:	Number of sister clades at that split

occurrence_node:	Node that carries the mutation
offspring_with:	Descendants of the mutated clade
median_offspring_without:	Median size of sister clades without the mutation
single_roho:	log10(offspring_with / median_offspring_without)

RoHo = log₁₀(# descendants with mutation / median # without)

https://www.nature.com/articles/s41467-020-19818-2

https://usher-wiki.readthedocs.io/en/latest/tutorials.html

https://usher-wiki.readthedocs.io/en/latest/matUtils.html

Import libraries
"""

import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""Data Loading"""

rdf = pd.read_csv('.../roho_scores.tsv',sep='\t', encoding="utf-8", low_memory=False, index_col=False)

rdf.head(30)

""" Initial Exploration"""

by_mut_rohos = []
for m, sdf in rdf.groupby("mutation"):
    if sdf.shape[0] >= 3:
        by_mut_rohos.append(np.mean(sdf.single_roho))

"""Visualization"""

max(by_mut_rohos)
plot = sns.displot(by_mut_rohos)

plot.savefig('rho_score.png')

# import numpy as np
# import pandas as pd
# import seaborn as sns
# import matplotlib.pyplot as plt

# rdf = pd.read_csv(
#     "roho_scores.tsv", sep="\t", encoding="utf-8", low_memory=False, index_col=False
# )
# by_mut_rohos = []
# for m, sdf in rdf.groupby("mutation"):
#     if sdf.shape[0] >= 3:
#         by_mut_rohos.append(np.mean(sdf.single_roho))

# max(by_mut_rohos)
# plot = sns.displot(by_mut_rohos)
# plt.savefig('output.png')

rdf.head(2)

rdf['single_roho'] = rdf['single_roho'].astype(int)

rdf.head

rdf.groupby('mutation').agg({'single_roho': ['mean', 'count']})

rdf.groupby('mutation').agg({'single_roho': ['mean', 'count']}).sort_values(('single_roho', 'mean'), ascending=False)



by_mut_rohos = []
for m, sdf in rdf.groupby("mutation"):
    if sdf.shape[0] >= 3:
        by_mut_rohos.append(np.mean(sdf.single_roho))
print(np.mean(by_mut_rohos))
sns.displot(by_mut_rohos)

top_mutations = rdf.groupby('mutation').agg({'single_roho': ['mean', 'count']}).sort_values(('single_roho', 'mean'), ascending=False)
top_mutations

"""Descriptive Stats and Filtering

"""

# Group by mutation and calculate average and count
mutation_stats = rdf.groupby('mutation').agg(
    avg_roho=('single_roho', 'mean'),
    n_occurrences=('single_roho', 'count')
).sort_values('avg_roho', ascending=False)

# Filter to mutations with ≥3 occurrences
filtered = mutation_stats[mutation_stats.n_occurrences >= 3]

top_10 = filtered.head(10)
bottom_10 = filtered.tail(10)

top_10

bottom_10

import seaborn as sns
import matplotlib.pyplot as plt

sns.displot(filtered['avg_roho'], kde=True)
plt.title("Distribution of Mean RoHo Scores by Mutation")
plt.xlabel("Average RoHo Score")

mutation_counts = rdf['mutation'].value_counts()
sns.histplot(mutation_counts, bins=30)

from scipy.stats import spearmanr
counts = mutation_counts.loc[rdf['mutation']].reset_index(drop=True)
corr, p = spearmanr(counts, rdf['single_roho'])
print(f"Spearman ρ: {corr:.2f}, p = {p:.2e}")

mean = filtered['avg_roho'].mean()
std = filtered['avg_roho'].std()
outliers = filtered[(filtered['avg_roho'] > mean + 2*std) | (filtered['avg_roho'] < mean - 2*std)]

outliers.head(5)

"""Gene Annotation

Uses SARS-CoV-2 reference genome coordinates to annotate genes
and classify as 'genic' or 'intergenic' mutation

Adds biological meaning — e.g., A23403G → Spike gene → genic

Extracts numeric genomic position from mutation strings like A22106T


Maps the mutation position to a known SARS-CoV-2 gene
"""

import pandas as pd

# SARS-CoV-2 gene coordinate ranges (based on NC_045512.2)
gene_ranges = {
    'ORF1ab': (266, 21555),
    'S': (21563, 25384),
    'ORF3a': (25393, 26220),
    'E': (26245, 26472),
    'M': (26523, 27191),
    'ORF6': (27202, 27387),
    'ORF7a': (27394, 27759),
    'ORF7b': (27756, 27887),
    'ORF8': (27894, 28259),
    'N': (28274, 29533),
    'ORF10': (29558, 29674),
}

# Extract numeric position from mutation string like "A22106T"
def extract_position(mutation):
    import re
    match = re.search(r'\d+', mutation)
    return int(match.group()) if match else None

# Map position to gene and region class
def get_gene_and_class(pos):
    for gene, (start, end) in gene_ranges.items():
        if start <= pos <= end:
            return gene, 'genic'
    return 'intergenic', 'intergenic'

# Apply extraction and annotation
rdf['pos'] = rdf['mutation'].apply(extract_position)
rdf[['gene', 'region_class']] = rdf['pos'].apply(
    lambda p: pd.Series(get_gene_and_class(p))
)
rdf['mutation_type'] = 'unknown'  # You can refine this later

# Preview
print(rdf[['mutation', 'pos', 'gene', 'region_class']].head())

# aggregate per mutation
annotated_df = rdf.groupby('mutation').agg(
    avg_roho=('single_roho', 'mean'),
    n_occurrences=('single_roho', 'count'),
    region_class=('region_class', 'first'),  # Use first since it's same for all rows per mutation
    gene=('gene', 'first')
).reset_index()

# Filter to mutations with at least 3 occurrences
annotated_df = annotated_df[annotated_df.n_occurrences >= 3]

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(data=annotated_df, x='gene', y='avg_roho')
plt.title("Average RoHo Score by Genomic Region (Genic vs Intergenic)")
plt.ylabel("Average RoHo Score")
plt.xlabel("Gene")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(data=annotated_df, x='region_class', y='avg_roho')
plt.title("Average RoHo Score by Genomic Region (region_class vs Intergenic)")
plt.ylabel("Average RoHo Score")
plt.xlabel("Gene")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(data=rdf, x='region_class', y='single_roho')
plt.title("RoHo Score Distribution by Genomic Region")
plt.xlabel("Region Type")
plt.ylabel("Single RoHo Score")
plt.grid(True)
plt.show()

gene_roho = rdf[rdf['region_class'] == 'genic'].groupby('gene')['single_roho'].mean().sort_values()

gene_roho.plot(kind='barh', title="Mean RoHo Score per Gene", figsize=(8,5))
plt.xlabel("Average RoHo")
plt.tight_layout()
plt.grid(True)
plt.show()

top10 = rdf[(rdf['region_class'] == 'genic')]
top10 = top10.groupby('mutation').agg(
    avg_roho=('single_roho', 'mean'),
    gene=('gene', 'first'),
    count=('mutation', 'count')
).sort_values('avg_roho', ascending=False).head(10)

print(top10)

hits = rdf[rdf['region_class'] == 'genic'].groupby('mutation').agg(
    avg_roho=('single_roho', 'mean'),
    count=('mutation', 'count'),
    gene=('gene', 'first')
).query("count >= 3 and avg_roho >= 0.3")

print(hits)

threshold = annotated_df['avg_roho'].quantile(0.75)
annotated_df['high_roho'] = (annotated_df['avg_roho'] >= threshold).astype(int)

features = annotated_df[['gene', 'region_class', 'n_occurrences', 'high_roho']].copy()

# One-hot encode gene and region_class
features = pd.get_dummies(features, columns=['gene', 'region_class'])

"""Machine Learning Pipeline

Random Forest
Trains a baseline model to classify mutations as high/low RoHo
Uses balanced class weights due to class imbalance

SMOTE Oversampling

Applies SMOTE to synthetically balance the minority class (high_roho=1)


Feature Importance
Visualizes which features (e.g., gene_S, region_class_genic) most influence predictions

 Evaluates models using ROC AUC — critical for imbalanced binary tasks


"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

X = features.drop("high_roho", axis=1)
y = features["high_roho"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#model = RandomForestClassifier(random_state=42)
model = RandomForestClassifier(random_state=42, class_weight='balanced')
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

from imblearn.over_sampling import SMOTE

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X, y)

model.fit(X_res, y_res)

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(class_weight='balanced')
lr.fit(X_res, y_res)

import matplotlib.pyplot as plt

importances = model.feature_importances_
feat_names = X.columns
sorted_idx = importances.argsort()[::-1]

plt.figure(figsize=(10,6))
plt.bar(range(len(importances)), importances[sorted_idx], align='center')
plt.xticks(range(len(importances)), feat_names[sorted_idx], rotation=90)
plt.title("Feature Importance (Random Forest)")
plt.tight_layout()
plt.show()

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

lr = LogisticRegression(class_weight='balanced', max_iter=500)
lr.fit(X_scaled, y)

sns.boxplot(data=annotated_df, x='high_roho', y='n_occurrences')

from sklearn.metrics import roc_auc_score
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])
print("ROC AUC:", roc_auc)

annotated_df['predicted_prob'] = model.predict_proba(X)[:,1]
top_preds = annotated_df.sort_values('predicted_prob', ascending=False).head(20)

top_preds.head(500)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X = features.drop("high_roho", axis=1)
y = features["high_roho"]
model = RandomForestClassifier().fit(X, y)



"""ML MODEL XGBoost

XGBoost Classification on RoHo Data

1. Prepare Data
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score
import xgboost as xgb

# Select features
features = annotated_df[['gene', 'region_class', 'n_occurrences', 'high_roho']].copy()

# One-hot encode categorical variables
features = pd.get_dummies(features, columns=['gene', 'region_class'])

# Split X and y
X = features.drop('high_roho', axis=1)
y = features['high_roho']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

"""2. Train XGBoost Model"""

# Initialize XGBoost
model = xgb.XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=(len(y) - sum(y)) / sum(y),  # auto-balance positive class
    eval_metric='auc',
    use_label_encoder=False,
    random_state=42
)

# Fit model
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

"""3. Evaluate Performance"""

# AUC Score
auc = roc_auc_score(y_test, y_prob)
print(f"ROC AUC: {auc:.3f}")

# Classification report
print(classification_report(y_test, y_pred))

"""4. Feature Importance"""

import matplotlib.pyplot as plt

xgb.plot_importance(model, max_num_features=10)
plt.title("Top 10 Feature Importances (XGBoost)")
plt.tight_layout()
plt.show()

"""Hyperparameter Tuning with GridSearchCV (XGBoost)

Add Cross-Validated Grid Search
"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'n_estimators': [100, 200],
    'subsample': [0.8, 1.0],
    'scale_pos_weight': [(len(y) - sum(y)) / sum(y)]  # keeps class balance
}

xgb_model = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='auc',
    use_label_encoder=False,
    random_state=42
)

grid_search = GridSearchCV(
    xgb_model,
    param_grid,
    scoring='roc_auc',
    cv=5,
    verbose=1,
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

# Best model
best_model = grid_search.best_estimator_
print("Best params:", grid_search.best_params_)

"""2. Evaluate Best Model"""

y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:, 1]

print(f"ROC AUC (tuned): {roc_auc_score(y_test, y_prob):.3f}")
print(classification_report(y_test, y_pred))

"""SHAP-Based Interpretation (Model Explainability)"""

import shap

# Use TreeExplainer for XGBoost
explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(X_test)

# Summary plot
shap.summary_plot(shap_values, X_test, plot_type="bar", show=True)

"""Compare with LightGBM"""

import lightgbm as lgb

lgb_model = lgb.LGBMClassifier(
    class_weight='balanced',
    random_state=42
)
lgb_model.fit(X_train, y_train)

y_prob_lgb = lgb_model.predict_proba(X_test)[:, 1]
print("ROC AUC (LightGBM):", roc_auc_score(y_test, y_prob_lgb))

"""** a compare_models() function that:**

Trains RandomForest, XGBoost, and LightGBM

(Optionally) tunes XGBoost using GridSearchCV

Evaluates each model with ROC AUC, classification report, and plots

Displays all AUCs side-by-side for easy comparison
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb
import lightgbm as lgb
import matplotlib.pyplot as plt
import shap
import seaborn as sns
import pandas as pd

def compare_models(features_df, label_col='high_roho'):
    # Preprocessing
    features = features_df.copy()
    X = features.drop(label_col, axis=1)
    y = features[label_col]

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42)

    # Store results
    results = {}

    # Random Forest
    rf = RandomForestClassifier(class_weight='balanced', random_state=42)
    rf.fit(X_train, y_train)
    rf_prob = rf.predict_proba(X_test)[:, 1]
    results['RandomForest'] = roc_auc_score(y_test, rf_prob)

    # XGBoost (tuned)
    scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)
    xgb_model = xgb.XGBClassifier(
        objective='binary:logistic',
        eval_metric='auc',
        use_label_encoder=False,
        scale_pos_weight=scale_pos_weight,
        random_state=42
    )

    param_grid = {
        'max_depth': [3, 5],
        'learning_rate': [0.05, 0.1],
        'n_estimators': [100, 200],
        'subsample': [0.8, 1.0]
    }

    grid = GridSearchCV(
        xgb_model, param_grid, scoring='roc_auc', cv=3, n_jobs=-1, verbose=0)
    grid.fit(X_train, y_train)
    xgb_best = grid.best_estimator_
    xgb_prob = xgb_best.predict_proba(X_test)[:, 1]
    results['XGBoost'] = roc_auc_score(y_test, xgb_prob)

    # SHAP plot for XGBoost
    explainer = shap.TreeExplainer(xgb_best)
    shap_values = explainer.shap_values(X_test)
    shap.summary_plot(shap_values, X_test, plot_type='bar', show=False)
    plt.title("XGBoost Feature Importance (SHAP)")
    plt.tight_layout()
    plt.show()

    # LightGBM
    lgb_model = lgb.LGBMClassifier(class_weight='balanced', random_state=42)
    lgb_model.fit(X_train, y_train)
    lgb_prob = lgb_model.predict_proba(X_test)[:, 1]
    results['LightGBM'] = roc_auc_score(y_test, lgb_prob)

    # Final AUC Comparison
    print("\nModel AUC Scores:")
    for model, auc in results.items():
        print(f"{model}: {auc:.4f}")

    # Bar plot
    plt.figure(figsize=(6,4))
    sns.barplot(x=list(results.keys()), y=list(results.values()))
    plt.ylabel("ROC AUC Score")
    plt.title("Model Comparison on RoHo Prediction")
    plt.ylim(0.5, 1.0)
    plt.tight_layout()
    plt.show()

# features should already be prepared (e.g., one-hot encoded)
compare_models(features)



!pip install catboost

"""CatBoost for RoHo Mutation Prediction"""

from catboost import CatBoostClassifier, Pool
from sklearn.metrics import roc_auc_score, classification_report

# Prepare features
df = annotated_df[['gene', 'region_class', 'n_occurrences', 'high_roho']].copy()
X = df.drop("high_roho", axis=1)
y = df["high_roho"]

# CatBoost can use categorical columns as-is (just tell it which ones)
cat_features = ['gene', 'region_class']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Define CatBoost
model = CatBoostClassifier(
    iterations=500,
    learning_rate=0.1,
    depth=6,
    cat_features=cat_features,
    class_weights=[1, 3],  # balance positives
    eval_metric='AUC',
    verbose=0,
    random_state=42
)

# Fit
model.fit(X_train, y_train)

# Predict
y_prob = model.predict_proba(X_test)[:, 1]
y_pred = model.predict(X_test)

# Evaluate
print("CatBoost AUC:", roc_auc_score(y_test, y_prob))
print(classification_report(y_test, y_pred))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.model_selection import train_test_split, GridSearchCV
from catboost import CatBoostClassifier

import xgboost as xgb
import lightgbm as lgb
import matplotlib.pyplot as plt
import shap
import seaborn as sns
import pandas as pd

def compare_models(features_df, label_col='high_roho'):
    # Preprocessing
    features = features_df.copy()
    X = features.drop(label_col, axis=1)
    y = features[label_col]

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42)

    # Store results
    results = {}

    # Random Forest
    rf = RandomForestClassifier(class_weight='balanced', random_state=42)
    rf.fit(X_train, y_train)
    rf_prob = rf.predict_proba(X_test)[:, 1]
    results['RandomForest'] = roc_auc_score(y_test, rf_prob)

    # XGBoost (tuned)
    scale_pos_weight = (len(y_train) - sum(y_train)) / sum(y_train)
    xgb_model = xgb.XGBClassifier(
        objective='binary:logistic',
        eval_metric='auc',
        use_label_encoder=False,
        scale_pos_weight=scale_pos_weight,
        random_state=42
    )

    param_grid = {
        'max_depth': [3, 5],
        'learning_rate': [0.05, 0.1],
        'n_estimators': [100, 200],
        'subsample': [0.8, 1.0]
    }

    grid = GridSearchCV(
        xgb_model, param_grid, scoring='roc_auc', cv=3, n_jobs=-1, verbose=0)
    grid.fit(X_train, y_train)
    xgb_best = grid.best_estimator_
    xgb_prob = xgb_best.predict_proba(X_test)[:, 1]
    results['XGBoost'] = roc_auc_score(y_test, xgb_prob)

    # SHAP plot for XGBoost
    explainer = shap.TreeExplainer(xgb_best)
    shap_values = explainer.shap_values(X_test)
    shap.summary_plot(shap_values, X_test, plot_type='bar', show=False)
    plt.title("XGBoost Feature Importance (SHAP)")
    plt.tight_layout()
    plt.show()

    # LightGBM
    lgb_model = lgb.LGBMClassifier(class_weight='balanced', random_state=42)
    lgb_model.fit(X_train, y_train)
    lgb_prob = lgb_model.predict_proba(X_test)[:, 1]
    results['LightGBM'] = roc_auc_score(y_test, lgb_prob)

        # CatBoost
    cat_features = [i for i, col in enumerate(X.columns) if 'gene_' in col or 'region_class_' in col]  # If one-hot encoded
    # OR if you passed raw strings (not one-hot): use ['gene', 'region_class']

    catboost_model = CatBoostClassifier(
        iterations=500,
        learning_rate=0.1,
        depth=6,
        cat_features=cat_features,
        class_weights=[1, 3],
        eval_metric='AUC',
        verbose=0,
        random_state=42
    )
    catboost_model.fit(X_train, y_train)

    cat_prob = catboost_model.predict_proba(X_test)[:, 1]
    results['CatBoost'] = roc_auc_score(y_test, cat_prob)

    # Final AUC Comparison
    print("\nModel AUC Scores:")
    for model, auc in results.items():
        print(f"{model}: {auc:.4f}")

    # Bar plot
    plt.figure(figsize=(6,4))
    sns.barplot(x=list(results.keys()), y=list(results.values()))
    plt.ylabel("ROC AUC Score")
    plt.title("Model Comparison on RoHo Prediction")
    plt.ylim(0.5, 1.0)
    plt.tight_layout()
    plt.show()

# features should already be prepared (e.g., one-hot encoded)
compare_models(features)
